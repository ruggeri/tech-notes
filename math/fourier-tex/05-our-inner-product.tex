\section{Our Inner Product}

So now we must find an appropriate inner product for our function space.
An ``obvious'' analogue to the dot product is:

\begin{nedqn}
  \innerprod{f}{g}
\eqcol
  \int_{t \in \reals}
  f(t)g(t)
  \dt
\end{nedqn}

This won't exactly work. First of all, integration over the entire real
domain is a little tricky. It must involve a limit. Setting this aside,
there is another problem. Consider $\innerprod{\sin t}{\sin t}$. We want
this to be 1.0. But is that true? Consider just:

\begin{nedqn}
  \int_0^{2\pi} \sin^2 t \dt
\end{nedqn}

Note that $\sin t$ is periodic with period $2\pi$. Thus:

\begin{nedqn}
  \int_{k2\pi}^{(k+1)2\pi} \sin^2 t \dt
\eqcol
  \int_{k'2\pi}^{(k'+1)2\pi} \sin^2 t \dt
\end{nedqn}

no matter which choice of $k, k'$. But this is trouble, since if

\begin{nedqn}
  \int_0^{2\pi} \sin^2 t \dt
& > &
  0
\end{nedqn}

then we would have that the integral over the entire real domain is
infinite.

But let's look more closely on the integration from just 0 to $2\pi$.
Integrating over this domain gives us all the information we need.
Integrating over any other period would simply be the same and is thus
redundant. But does the integral come out correctly? Note:

\begin{nedqn}
  \int_0^{2\pi} \sin^2 t + \cos^2 t \dt
\eqcol
  \int_0^{2\pi} 1 \dt
=
  2\pi
\end{nedqn}

But note that:

\begin{nedqn}
  \int_0^{2\pi} \sin^2 t \dt
\eqcol
  \int_0^{2\pi} \cos^2 t \dt
\end{nedqn}

since one is merely a phase-shifted version of the other. Thus we see
that:

\begin{nedqn}
  \int_0^{2\pi} \sin^2 t \dt
\eqcol
  \pi
\end{nedqn}

That isn't exactly what we want, but it's a start. Another way to see
this is to remember that $\parens{\cos t, \sin t}$ is the position on
the circle at angle $t$. The square of the length of that vector is
always $1.0$, because the radius is always $1.0$. If you integrate all
the way around the circle, you should get $2\pi$. Of that, $\sin^2 t$ is
only half the story.

Note that the same argument holds for any $\sin kt$, so we know that
$\norm{\sin kt} = \pi$ for all $k$.

Anyway, to ``fix'' this problem, we should \emph{keep} our inner
product, but simply scale down our basis vectors to be
$\frac{1}{\sqrt{\pi}} \sin kt$.

The next important question: are two sinusoidals $\sin kt$ and $\sin k'
t$ orthogonal?

\subsection{Orthogonality of $\sin kt$ and $\sin k' t$}

Here's how I see it. Say the first of these waves is traveling faster
than the second (one has to be if $k \ne k'$). Then for every rotation
that the first sine wave makes, the second sine wave falls $\theta$
radians behind (for some $\theta$).

Let's start at $t_0 = 0$. Let's consider each the set of times $t_i$ at
which the first wave crosses zero again. In fact, let's consider
$\parens{\cos kt_i, \sin kt_i}$ as a pair. We'll consider the points
$t_i$ where $\parens{\cos kt_i, \sin kt_i} = \parens{1, 0}$.

Now, let's consider the corresponding $\parens{\cos k't_i, \sin k't_i}$.
We know this starts at $\parens{1, 0}$ for $t_0$, but subsequent $t_i$
will differ. As we said: each $\parens{\cos k't_i, \sin k't_i}$ falls
behind by a fixed angle $\theta$. Specifically, we know:

\begin{nedqn}
  \parens{\cos k't_m, \sin k't_m}
\eqcol
  \parens{\cos m\theta, \sin m\theta}
\end{nedqn}

Now, I claim the following:

\begin{nedqn}
  \sum_{m = 0}^n
  \parens{\cos m\theta, \sin m\theta}
\eqcol
  \parens{0, 0}
\end{nedqn}

\subsection{An Aside About Complex Numbers}

To see this, let's move to complex numbers. Complex numbers of norm 1.0
represent positions on the circle. The real part is along the $x$-axis,
and the imaginary part is along the $y$-axis.

Multiplication by a complex number corresponds to \emph{rotation}.
Consider $c = \parens{\cos \varphi, \sin \varphi}$ It's easy to see that
multiplying $1$ by $c$ maps $1$ to $c$. $1$ originally lived at
zero-degrees CCW from the $x$-axis. Now it corresponds to $\varphi$
degrees CCW from the $x$-axis.

Likewise one can consider $i$. $ci$ maps the $x$-coordinate of $c$ to
the $y$-coordinate. And the $y$-coordinate is mapped to the
$x$-coordinate, but in the opposite direction. This is exactly
corresponding to a CCW rotation of $i$.

\subsection{Completing Our Proof}

So repeated rotation of $\parens{1, 0}$ by $\theta$ can be expressed as:

\begin{nedqn}
  1, c, c^2 + \ldots, c^{n - 1}
\end{nedqn}

Now consider what would happen if we summed all these terms. We would
get zero. Why? Consider multiplying everything by $c$. The original $1$
becomes $c$, and note that the final $c^{n-1}$ becomes $1$. So you get
the same thing as you started with.

When does a $cx = x$? Either when $c = 1$ (no rotation), or when $x = 0$
(rotation does nothing to the zero vector).

We thus know that the sum is zero (since $c$ corresponds to a rotation
by $\varphi > 0$).

Thus the sum for of $\sin k't \cos k't$ at points $t_0, \ldots, t_n$ is
zero. And in fact this holds regardless of starting point $t_0 \ne 0$.
Thus:

\begin{nedqn}
  \int \sin kt \sin k't \dt
\eqcol
  0.0
\end{nedqn}

Thus the two are orthogonal.

\subsection{Linearity}

The projection operation is clearly linear, because:

\begin{nedqn}
  \int_0^{2\pi}
  \parens{f(t) + g(t)}
  \cdot
  h(t)
  \dt
\eqcol
  \int_0^{2\pi}
  f(t) \cdot h(t) \dt
  +
  \int_0^{2\pi}
  g(t) \cdot h(t) \dt
\end{nedqn}

So we now see that we have a nice inner product. It is linear in the
correct way, and it declares our chosen basis to be orthonormal. Thus we
can use it for decomposing a sinusoidal into the basis.

% Inspiration: https://math.stackexchange.com/questions/891875/

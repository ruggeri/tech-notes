\newcommand{\Fp}{\F_p}
\newcommand{\Fq}{\F_q}
\newcommand{\Fmodg}{\F[x]/(g)}
\newcommand{\Fpmod}[1]{\Fp[x]/(#1)}
\newcommand{\Fpmodg}{\Fpmod{g}}

\section{Finite Fields}

\subsection{Definitions}

\begin{remark}
  These notes are based off of:
  \url{https://web.stanford.edu/class/ee392d/Chap7.pdf}. Those notes are
  part of EE392d, a coding theory course at Stanford. This chapter is
  from the reading notes for that class.
\end{remark}

\begin{definition}
  A \define{monoid} is almost a group. The difference is that not every
  element need be invertible. The integers (either positive or
  non-negative) are a monoid with respect to multiplication.

  Like groups/abelian groups, monoids may be either commutative or
  non-commutative.
\end{definition}

\begin{definition}
  A \define{ring} is a set with $+, \cdot$ operations. The set is an
  abelian group with respect to $+$ (the identity is written 0).

  The group is a \define{monoid} with respect to multiplication. That
  is: multiplication is associative, and there is an identity 1.
  Elements, (even non-zero elements) may not be invertible.

  The distributive law is required to hold: $a(b + c) = ab + ac$.
\end{definition}

\begin{definition}
  A \define{commutative ring} is one in which the multiplication
  operation commutes. When a ring has a multiplication which is not
  commutative, we will emphasize this by calling it a
  \define{non-commutative ring}. When we just write ``ring,'' we'll
  assume it is a commutative ring.
\end{definition}

\begin{definition}
  A \define{field} is a commutative ring where every non-zero element
  has an inverse.
\end{definition}

\begin{definition}
  An \define{integral domain} is a commutative ring where whenever $xy =
  xz$ we may infer $y = z$. A integral domain is also called (more
  enlighteningly, but sadly more rarely) a \define{cancellation ring}.
\end{definition}

\begin{proposition}
  Any \emph{finite} integral domain $R$ must be a field.
\end{proposition}

\begin{proof}
  For every non-zero element $a$ and pair of distinct elements $b, c$,
  we know $ab \ne ac$. Thus each $ab$ is distinct. There are $\order{R}$
  distinct products, and exactly $\order{R}$ elements in the ring. So
  there exists some $b$ such that $ab = 1$.

  Note this proof doesn't work for \emph{infinite} integral domains like
  the integers or polynomials.
\end{proof}

\begin{definition}
  We can talk about a ``non-commutative field.'' When the multiplication
  operation is non-commutative, we call this a \define{division ring} or
  \define{skew field}.
\end{definition}

\begin{remark}
  Wedderburn's little theorem (which I have not studied) proves that all
  finite skew fields are in fact proper commutative fields. The only
  ``true'' skew fields are infinite.

  In this chapter, I will neither discuss infinite nor skew fields.
\end{remark}

\subsection{Every field with $p$ elements is isomorphic to $\Zmodp$}

\begin{theorem}
  $\Zmodn$ is a field exactly when $n$ is prime.
\end{theorem}

\begin{proof}
  The addition and multiplication operations are both commutative. The
  distributive law holds. These are facts on the integer operations, in
  terms of which $\Zmodn$ is defined.

  Both a 0 and 1 elements exist. Additive inverses always exist. Last,
  note that for all $x \in \Zmodn$, $x\Zmodn$ is a permutation when $n$
  is prime. Thus all $x$ are invertible when $n$ is prime. But this is
  not so when $n$ is composite.
\end{proof}

\begin{definition}
  The \define{integers} of a field $\F$ are the sums generated by
  repeated addition of 1: $0, 1, 1+1, 1+1+1, \ldots, p$.
\end{definition}

\begin{theorem}
  The integers of a finite field are always themselves a subfield. There
  are always a prime number of them. They are isomorphic to $\Zmodp$
  (for some prime $p$).
\end{theorem}

\begin{proof}
  Presuming that $\F$ is finite, the set of integers of $\F$ is also
  finite, and must wrap back to 0 eventually. (This is how we use our
  important presumption that $\F$ is finite.) So the integers are a
  cyclic group generated by $1$ with respect to addition.

  Next question: are the integers of $\F$ a \define{subfield}? We
  consider the product $ij$ of integers $i, j$. But we can use the
  distributive law:

  \begin{nedqn}
    ij
  \eqcol
    \parens{1_1 + 1_2 + \ldots + 1_i} \parens{1_1 + 1_2 + \ldots + 1_j}
  \\
  \eqcol
    1_1\parens{1_1 + 1_2 + \ldots + 1_j}
    + \ldots +
    1_2\parens{1_1 + 1_2 + \ldots + 1_j}
  \end{nedqn}

  \noindent
  This shows that $ij$ is just the result of adding $1$ to itself $ij$
  times. Which shows that the integers are isomorphic to $\Zmodn$. If
  $n$ were not prime, then multiplication by some $i$ in $\Zmodn$ is not
  injective. In this case, $\Zmodn$ is not a field, and neither can
  $\Field$ be.

  Since of course we've assumed $\F$ \emph{is} a field, we know that $n$
  must be prime and $\Zmodn$ must be a subfield.
\end{proof}

\begin{definition}
  The \define{characteristic} of a field $\F$ is the number of integers
  in $\F$. We've shown that a finite field $\F$ always has finite
  characteristic $p$, for $p$ prime.
\end{definition}

\begin{corollary}
  If the characteristic of $\F$ is $p$, then any field element $x$ added
  to itself $p$ times will always be zero.
\end{corollary}

\begin{proof}
  \begin{nedqn}
    x_1 + x_2 + \ldots + x_p
  \eqcol
    \parens{1_1 + 1_2 + \ldots + 1_p} x
  \\
  \eqcol
    0x
  \\
  \eqcol
    0
  \end{nedqn}
\end{proof}

\begin{theorem}
  Every finite field $\F$ of $p$ elements is isomorphic to $\Zmodp$.
\end{theorem}

\begin{proof}
  We know the integers are a subfield of $\F$. But Lagrange implies that
  the number of integers must divide $\order{\F} = p$. Since the number
  of integers must always be at least two (the integers always contains
  0 and 1), the number of integers must not trivially divide $p$. Thus
  the number of integers is in fact $p$, and thus $\F \cong \Zmodp$.
\end{proof}

\begin{definition}
  The finite field of $p$ elements is traditionally notated as $\GF{p}$.
  We call this the \define{Galois Field} of $p$ elements.

  However, I will denote $\GF{p}$ as $\Fp$ in this document, since this
  is less verbose but no less clear. This follows the practice in the
  Stanford reading.
\end{definition}

\subsection{Every finite field must have $p^k$ elements}

\begin{theorem}
  A finite field $\F$ must have $p^k$ elements (for some prime $p$ and
  any $k > 0$).
\end{theorem}

\begin{proof}
  Consider the additive group structure of $\F$. By the Fundamental
  Theorem of Finite Abelian Groups, this is isomorphic to a direct
  product $\prod \Zmod{p_i^{k_i}}$.

  One of these subgroups represents the integers of the field. WLOG
  presume this is $\Zmod{p_1^{k_1}}$. In fact, we've said the integers
  must have prime order $p_1$ with $k_1 = 1$.

  Now consider any other factor subgroup $\Zmod{p_i^{k_i}}$. I claim
  that $p_i = p_1$ and $k = 1$. Why? Because take a generator $x$ of the
  factor additive subgroup. We know that $p_1 x = 0$ ($p_1 x$ here
  simply denotes repeated addition), because $p_1$ is the characteristic
  of the field. So the (additive) order of $x$ must divide $p_i$. And
  because $p_i$ is prime, this can only happen if $\order{x} = p_i =
  p_1$.

  Thus all factor subgroups have the same order: $p$. Thus the field
  overall has exactly $p^k$ elements.
\end{proof}

\begin{corollary}
  No set of $ab$ elements (for $a, b$ coprime) can be a field.
\end{corollary}

\subsection{Polynomial Rings}

\begin{remark}
  We know that if a field $\F$ has $p^k$ elements, it must have additive
  structure isomorphic to coordinate-wise addition of integers modulo
  $p$: $i_1 \times \ldots \times i_{k-1}$.

  If we want to study what fields of $p^k$ elements are possible, the
  question becomes: what kind of multiplicative structures will be
  compatible with the distributive law?

  It will turn out that for each $p^k$, there is exactly one way of
  defining multiplication relative to addition such that the two match
  up and we get a field. This is what we are going to prove (in time).
\end{remark}

\begin{definition}
  A polynomial over a field $\F$ is an expression $f_0 + f_1x + \ldots +
  f_m x^m$. The ``coefficients'' $f_i$ are taken from $\F$. We can add
  polynomials coordinate-wise.

  We define the standard multiplication of polynomials by
  \define{convolution}. For two polynomials $f, g$, their product is a
  new polynomial $h$ where the coefficients of $h$ are given by:

  \begin{nedqn}
    h_i
  \eqcol
    \sum_{j = 0}^i
    f_j
    g_{i - j}
  \end{nedqn}
\end{definition}

\begin{proposition}
  We denote the space of all polynomials over a field $\F$ as $\F[x]$.
  This space is a (commutative) ring.
\end{proposition}

\begin{proof}
  The space is a commutative group with respect to addition. This is so
  because the additive structure is isomorphic to the direct product
  $\F^k$.

  The space is a commutative monoid with respect to multiplication.
  Multiplication is clearly commutative (since it is commutative in
  $\F$). Proving polynomial multiplication is associative takes just a
  little work that I won't bother with. The polynomial 1 is the
  multiplicative identity.

  It is simple to verify that the distributive law holds (again, because
  it already holds in $\F$), so this proves that we have a ring.
\end{proof}

\begin{remark}
  We normally think of polynomials as functions, where $x$ is a
  placeholder for an input to the function. Over $\R$, two polynomials
  are identical if and only if they define the same function.

  This is not necessarily true in other contexts. The reading gives an
  example that both $x, x^2$ define the same function over $\Zmod{2}$,
  even though the functions they define are both the same.

  This emphasizes that maybe we shouldn't think of polynomials quite
  like functions. They are simply expressions in a syntactic sense. The
  notation $\F[x]$ is really just meaning expressions written in a
  certain form. The $[x]$ part means ``adjoin'' an element to define a
  richer set of expressions. We could write $\F[x, y]$ to define an even
  fuller space of polynomials with $x^i y^j$ terms.
\end{remark}

\begin{proposition}
  $\F[x]$ is an integral domain: whenever $fg = fh$, we may infer $g =
  h$. However, $\F[x]$ is not a field.
\end{proposition}

\begin{proof}
  Consider $fg = fh$. Then $f \parens{g - h} = 0$ (distributive law).
  Consider the product of the lead terms of $f, g-h$. Can this be zero?
  No, since $\F$ is a field. (In fact, this is true even if $\F$ were
  merely an integral domain.)

  Thus two polynomials in $\F[x]$ can multiply to zero only if $f = 0$
  or $g - h = 0$. So it is safe to cancel when we know $f \ne 0$.

  Even though $\F[x]$ is an integral domain, it doesn't have inverses.
  Multiplying by a polynomial can never result in a new polynomial of
  lower degree. So \emph{no} polynomial (besides the integers) can have
  an inverse.
\end{proof}

\subsection{Polynomial Division and Factorization}

\begin{theorem}
  For any two polynomials $f, g$, there is a unique choice of $q, r$
  such that

  \begin{nedqn}
    f(x)
  \eqcol
    g(x)q(x) + r(x)
  \end{nedqn}

  \noindent
  where $\deg r < \deg g$.
\end{theorem}

\begin{proof}
  We can show this by considering the polynomial long division
  algorithm.
\end{proof}

\begin{definition}
  Polynomials with leading term 1 are called \define{monic} polynomials.
  If a polynomial cannot be written as the product of two non-constant
  polynomials, then the polynomial is called \define{irreducible}. A
  monic, irreducible polynomial is called a \define{prime polynomial}.
\end{definition}

\begin{proposition}
  Every monic polynomial has a unique factorization into prime
  polynomials.
\end{proposition}

\begin{proof}
  First: note that there is a single monic polynomial of degree zero
  ($f(x) = 1$) and it has a unique factorization. Assume that every
  monic polynomial of degree $n' < n$ has a unique factorization into
  prime polynomials. Take a monic polynomial $f$ with degree $n$. Our
  goal is to show that this, too, has a unique factorization into prime
  polynomials.

  We will show this by contradiction. Assume that $f$ factors into
  $\prod_{i = 1}^{m_p} p_i$ and also $\prod_{j = 1}^{m_q} q_j$. Choose a
  factor with the \emph{lowest degree}. We may assume that this is
  $p_1$.

  It is clear from the factorization of $f$ into $p_i$ that $f \bmod
  p_1$ must be zero. Thus the product of $q_j \bmod p_1$ must also be
  zero. This sounds suspicious. Let's rewrite each $q_j$ as $a_j p_1 +
  b_j$, where $b_j$ must have degree strictly less than $p_1$. Thus:

  \begin{nedqn}
    f
  \equivcol
    0 \pmod{p_1}
  \\
    \prod_{j=1}^{m_q} q_j
  \equivcol
    0 \pmod{p_1}
  \\
    \prod_{j=1}^{m_q} \parens{a_j p_1 + b_j}
  \equivcol
    0 \pmod{p_1}
  \\
    \prod_{j=1}^{m_q} b_j
  \equivcol
    0 \pmod{p_1}
  \intertext{This tells us that there exists a polynomial $c$ such that:}
    \prod_{j=1}^{m_q} b_j
  \eqcol
    c p_1
  \end{nedqn}

  Naturally no $b_j = p_1$, since it is a remainder modulo $p_1$. Thus
  we know that however $c$ might factor into various $c_k$, we will have
  two distinct factorizations of the same polynomial: $\prod_{j=1}^{m_q}
  b_j$ and $p_1 \prod_k c_k$.

  But note that the degree of $\prod_{j=1}^{m_q} b_j$ must be
  \emph{strictly less} than the degree of $\prod_{j=1}^{m_q} q_j$. Why?
  The degree of $p_1$ is never greater than the degree of $q_j$. The
  degree of the remainder $b_j$ is always strictly less than $p_1$ and
  thus also $q_j$.

  We have now found a contradiction to our induction hypothesis, and the
  unique factorization theorem is thus proven.
\end{proof}

\subsection{Polynomial Quotient Rings and Fields}

\begin{definition}
  We may define polynomials over $\F$ \define{modulo} a polynomial $g$.
  We denote this $\Fmodg$. This is called a \define{quotient ring},
  similar to the concept of a quotient group. The notation $(g)$ means
  the \define{ideal} generated by $g$. I don't want to get bogged down
  into the general definition of ideals and quotients though.
\end{definition}

\begin{proposition}
  Let $g$ be a polynomial over $\F$ with degree $n$. $\Fmodg$ is a ring.
  $\Fmodg$ consists of exactly the polynomials with degree less than
  $n$.
\end{proposition}

\begin{proof}
  The typical polynomial addition and multiplication operations modulo
  $g$ remain associative and commutative. 0 and 1 identities still
  exist. Additive inverses still exist. The distributive law still
  holds. Thus we still have a ring.

  Note every polynomial $f$ with degree less than $\deg g$ is already a
  remainder modulo $g$. But note that every polynomial $f$ with degree
  greater or equal to $\deg g$ reduces to a polynomial with lesser
  degree. Thus we know that the elements of $\Fmodg$ are exactly the
  polynomials with $\deg f < \deg p$.
\end{proof}

\begin{corollary}
  If $\F$ is finite, then $\Fmodg$ has $\order{\F}^k$ elements, where $n
  = \deg g$.
\end{corollary}

\begin{proposition}
  $\Fmodg$ is a field exactly if $g$ is irreducible over $\F$.
\end{proposition}

\begin{proof}
  If $g$ is reducible, note that non-zero factors $f_1, f_2$ multiply to
  $g$. Then we know that $f_1 f_2 \equiv 0 \pmod{g}$. So we know that
  $\Fmodg$ cannot be an integral domain, much less a field.

  So consider any $g$ that is irreducible. Consider the possibility that
  $f f' \equiv 0 \pmod{g}$. If we prove this can't happen then we prove
  that $\Fmodg$ is a field.

  I argue that this cannot happen. We don't quite know that $f f'$ is a
  factorization of $g$, but consider that $f f' = qg$. Clearly at least
  one of $f, f'$ must have a common factor with $g$ (by unique
  factorization). Which would contradict our presumption that $g$ is
  irreducible.

  Note that we have not presumed that $\F$ is finite.
\end{proof}

\begin{corollary}
  If there exists a degree-$k$ irreducible polynomial over $\Fp$, we can
  construct a new field of order $p^k$.
\end{corollary}

\begin{remark}
  Some questions remain:

  \begin{enumerate}
    \item Does there always exist a degree-$k$ irreducible polynomial
    over $\Fp$?

    \item Does it matter what irreducible polynomial $g$ you choose?
    Will you get different fields?

    \item Are all fields $\F$ isomorphic to $\Fpmodg$ for some $g$?
  \end{enumerate}
\end{remark}

\subsection{The Multiplicative Group $\F^\times$ Is Always Cyclic}

\begin{theorem}
  If $\F$ is a field, then its multiplicative group $\F^\times$ is
  cyclic.
\end{theorem}

\begin{proof}
  This proof is the same as my proof that $\Zmodp$ is cyclically
  generated. By Lagrange's theorem, we know that every element $x\in\F$
  has order dividing $\order{\F^\times}$. That is:

  \begin{nedqn}
    x^{\order{\F^\times}} - 1
  \eqcol
    0
  \end{nedqn}

  \noindent
  has $\order{\F^\times}$ solutions. Could there be a $d$ properly
  dividing $\order{\F^\times}$ such that always $x^d - 1 = 0$? No,
  because this polynomial can only have at most $d$ roots, by the
  Fundamental Theorem of Algebra. The theorem applies because the
  polynomial is over $\F$ a field.

  We shouldn't exactly jump to conclude that thus there exists an
  $\alpha\in\F$ with order $\order{\F^\times}$. We should either use a
  lemma that (1) if the ``exponent'' of a group is $m$, there exists an
  element of order $m$, \emph{or} (2) if there exists no more than one
  subgroup of order $d$ for each $d$ dividing $\order{G}$, then $G$ must
  be cyclic.

  Anyway, that will let us finally conclude that there does indeed exist
  an $\alpha$ such that $\alpha^d - 1 \ne 0$ for any $d <
  \order{\F^\times}$. In which case $\F^\times$ is cyclically generated
  by $\alpha$.
\end{proof}

\begin{proposition}
  Consider a finite field $\F$ with $p^k$ elements. Consider the
  polynomial $x^{p^k - 1} - 1$. Then the polynomial $x^{p^k - 1} - 1$
  factors into $\prod_{\alpha \in \F^\times} \parens{x - \alpha}$.
\end{proposition}

\begin{proof}
  By the Fundamental Theorem, we know that $x^{p^k - 1} - 1$ can have at
  most $p^k - 1$ roots. But we know that the multiplicative group
  $\F^\times$ consists of exactly $p^k - 1$ elements, and thus the order
  of each element $\alpha$ must divide $p^k - 1$. Thus each element
  $\alpha \in \F^\times$ is a root of $x^{p^k - 1}$.

  (Note: it doesn't really matter here that $\F^\times$ is cyclic. We
  only need to use Lagrange.)
\end{proof}

\begin{corollary}
  For $\F$ with order $p^k$, $x^{p^k} - x = \prod_{\beta\in\F} \parens{x
  - \beta}$.
\end{corollary}

\subsection{Finite Fields Are Isomorphic To Polynomial Quotient Fields}

\begin{remark}
  This approach is my own! With some help from JRN!
\end{remark}

\begin{lemma}
  Let $\F$ be a field with $p^k$ elements. Then it requires $k$ linearly
  independent $x_0, \ldots, x_{k-1}$ to span all of $\F$.
\end{lemma}

\begin{proof}
  We've previously shown that a a field of $p^k$ elements must have
  additive structure isomorphic to the direct product of $k$ copies of
  $\Zmodp$. This follows from the requirement that the characteristic of
  a finite field must always be prime.

  It follows that $k$ (and no fewer) linearly independent elements of
  $\F$ will span the entire space $\F$.
\end{proof}

\begin{lemma}
  Let $\F$ be a field with $p^k$ elements. Then we can choose $x$ such
  that $x^0, x^1, \ldots, x^{k-1}$ are all linearly independent.
\end{lemma}

\begin{proof}
  Now, we know that there exists some $x^1$ that generates all of
  $\F^\times$ through repeated multiplication (since $\F^\times$ is
  cyclic). Note that $x^1$ cannot be in the span of $x^0 = 1$, since
  this would imply that $x^1$ is an integer. We know that the product of
  integers must remain an integer, and thus $x^1$ could not generate
  $\F^\times$. (Exception: this is fine if $k = 1$.)

  I will argue that each successive $x^i$ is linearly independent from
  the preceding choices for $i < k$.

  If $x^i$ is not linearly independent of the preceding choices, then no
  further power of $x$ can be either. The reason is that then the
  product $x^{i+1} = x^1 x^i$ could be written as $x^1 \sum_{j = 0}^{i -
  1} a_j x^k$. We could apply the distributive law to distribute $x^1$,
  which gives us $\sum_{j=1}^{i} a_j x^j$. But we could replace the
  final $x^i$ term with a linear combination of lower order terms. Which
  shows that this sum would remain in the span of the prior $x^0,
  \ldots, x^{i - 1}$.

  Thus the first $k$ choices $x^0, \ldots, x^{k - 1}$ must all be
  linearly independent. If not, then powers of $x^1$ could never yield a
  set of $k$ linearly independent elements of $\F$ which we know exists.
\end{proof}

\begin{lemma}
  There exists a homomorphism from $\parens{\Zmodp}[x]$ into a finite
  field $\F$ of $p^k$ elements.
\end{lemma}

\begin{proof}
  Our prior lemma has allowed us to write any element of $\F$ as a
  linear combination of the $x^0, \ldots, x^{k-1}$. In other words, we
  can write any element as a polynomial over $\Zmodp$. The usual
  polynomial addition and multiplication operations exactly correspond
  to the addition and multiplication in $\F$. (Note, it matters that we
  chose $x^0 = 1$, so that multiplication of the constant term gave
  another constant! If we hadn't done so, the $2f \ne f + f$!)

  Good news: the homomorphism is surjective onto $\F$ because
  $\parens{\Zmodp}[x]$ contains all powers $x^i$, which we associate
  with powers of a generator in $\F$.

  Bad news: there are an infinite number of equivalent representations
  in $\parens{\Zmodp}[x]$ for each element of $\F$. Polynomials with
  degree greater than $k-1$ are always equivalent to some polynomial
  with degree less than $k$. We know this because the first $k$ choices
  of $x^0, \ldots x^{k-1}$ already span all of $\F$.

  In summary: there is a homomorphism from $\parens{\Zmodp}[x]$ and
  $\F$. But it is not an isomorphism, since the homomorphism is not
  injective.
\end{proof}

\begin{theorem}
  Let $\F$ be a finite field of order $p^k$. There exists an
  irreducible, degree-$k$ polynomial $g$ over $\Zmodp$ such that $\F$ is
  isomorphic to $\Fpmodg$.
\end{theorem}

\begin{proof}
  How can we reduce polynomials with degree greater than $k-1$ to
  equivalent polynomials of degree less than $k$? It suffices to know
  $a_0, \ldots, a_{k-1}$ such that $x^k = \sum_{i=0}^{k-1} a_i x^i$. We
  may thus rewrite a degree $k$ polynomial as a degree $k-1$ polynomial.
  Likewise we can reduce polynomials of higher degrees step-by-step.

  What we are doing, effectively, is mapping a polynomial $f$ to its
  remainder modulo $g(x) = x^k - \sum_{i=0}^{k-1} a_i x^i$. I claim that
  $g$ must be irreducible. If it were not, there would be two non-zero
  polynomials $f_1, f_2$ such that $f_1 f_2 \equiv 0$. But then there
  would be corresponding non-zero elements of $\F$ that multiply to
  zero. We know that would violate the existence of multiplicative
  inverses in $\F$.

  Thus we know the finite field $\F$ is isomorphic to a quotient field
  $\Fpmodg$ for some irreducible $g$.
\end{proof}

\begin{remark}
  Some questions remain:

  \begin{enumerate}
    \item Does there always exist a degree-$k$ irreducible polynomial
    over $\Fp$?

    \item Equivalently: does there always exist a field $\F$ of order
    $p^k$?

    \item Does it matter what irreducible polynomial $g$ you choose?
    Will you get different fields?

    \item Equivalently: are all fields of order $p^k$ isomorphic?
  \end{enumerate}
\end{remark}

\subsection{Minimal Polynomials}

\begin{remark}
  This approach will more closely follow the Stanford handout chapter I
  was reading.
\end{remark}

\begin{definition}
  Consider a field $\Fq$ with $p^k$ elements. Let $\Fp$ be the prime
  subfield of integers of $\Fq$. Note that polynomials over $\Fp[x]$ can
  also be viewed as polynomials over $\Fq[x]$. A polynomial $g_\beta \in
  \Fp[x]$ is called a \define{minimal} polynomial for $\beta \in \Fq$ if
  (1) $g_\beta(\beta) = 0$, and (2) there is no other $h \in Fp[x]$ with
  lesser degree such that $h(\beta) = 0$.
\end{definition}

\begin{proposition}
  If $f \in \Fp[x]$ satisfies $f(\beta) = 0$, then the minimal
  polynomial $g_\beta$ must divide $f$.
\end{proposition}

\begin{proof}
  Consider if $f = qg_\beta + r$. Then $r(\beta) = 0$. Since $g_\beta$
  was presumed minimal, it must be that $r = 0$. In which case $f$ is a
  multiple of $g$.
\end{proof}

\begin{corollary}
  If $\deg f = \deg g_\beta$, then $f = g_\beta$.
\end{corollary}

\begin{proposition}
  A minimal polynomial $g_\beta$ must be irreducible over $\Fp$.
\end{proposition}

\begin{proof}
  Otherwise we could factor into $g_1, g_2$ (each with lesser degree
  than $g_\beta$). But then at least one of $g_1(\beta), g_2(\beta)$
  would have to equal zero.
\end{proof}

\begin{proposition}
  For every $\beta \in \Fq$, there exists a minimal polynomial $g_\beta
  \in \Fp[x]$.
\end{proposition}

\begin{proof}
  It suffices to show that there exists \emph{any} polynomial $g \in
  \Fp[x]$ satisfying $g(\beta)$. So long as there is at least
  \emph{one}, then somebody must be minimal.

  Consider the polynomial $x^{p^k} - x$. Since this is a polynomial in
  $\Fp[x]$, we may factor it into irreducible polynomials $g_i$ over
  $\Fp$ st $x^{p^k} - x = \prod_i g_i$. At the same time, we may factor
  it over $\Fq$. Over $\Fq$ this trivially factors into $x^{p^k} - x =
  \prod_{\beta\in\Fq} (x - \beta)$ because Lagrange.

  This shows us that for any $\beta\in\Fq$, $(x - \beta)$ must be a
  factor of (exactly) one of the $g_i$. Which shows us there is always a
  minimal polynomial for $\beta_j$ in $\Fp$.
\end{proof}

\begin{proof}
  To speak with fewer symbols...

  We want to show there always exists \emph{some} non-zero polynomial in
  $\Fp[x]$ where $\beta\in\Fq$ is a root. If so, then it follows
  naturally that \emph{some} divisor polynomial must be minimal. Showing
  there exists a polynomial with $\beta$ as a root amounts to saying:
  there are at least \emph{two} ways to write each $\beta$ as linear
  combinations of powers of $\beta$ with coefficients in $\Fp$. We'll
  show this.

  So just consider taking powers of $\beta$. We know that this must
  eventually return to $\beta$ (e.g., by Lagrange, after $p^k$ steps).
  So we have our two ways of writing $\beta$ ($x, x^{p^k}$) and they
  only use $1, -1$ coefficients in $\Fp$. It follows that $x^{p^k} - x$
  is a polynomial with $\beta$ as a root.

  That suffices to prove our claim, but let us think less gratuitously.
  Start taking powers of some $\beta$. When are we \emph{for sure} going
  to get something that lies in the span of $\beta$? Wait: what do we
  mean ``span'' of $\beta$? What coefficients should we use? It makes
  sense to think of the span of $\beta^i$ as integer multiples
  $k\beta^i$. This is exactly what you get from repeated addition of
  $\beta^i$. So let's choose the integers of $\Fq$ as the coefficients.

  The integers of $\Fq$ are $\Fp$, so the characteristic of $\Fq$ is
  $p$, so there are $p$ multiplies of $\beta^0$. Likewise $p$ multiples
  of $\beta^1$, et cetera. So there at most $k$ linearly independent
  powers $\beta^i$. Once you let in $\beta^k$, you have something that
  is for sure linearly dependent in the prior powers of $\beta$.

  Such a polynomial of degree $k$ (or less, if $\beta$ generates a
  subfield strictly smaller than all of $\Fq$) is called
  \define{minimal} for $\beta$. It's a second way to write $\beta$. No
  polynomial with degree less than $k$ will do.

  This construction of the minimal polynomial exactly mimics what I did
  in my own proof above that any $\F$ is isomorphic to some $\Fpmodg$.
\end{proof}

\begin{theorem}
  $\F$ of order $p^k$ is isomorphic to $\Fpmodg$, for some $k$-degree
  polynomial $g$ irreducible over $\Fp$.
\end{theorem}

\begin{proof}
  Again this is basically identical to my earlier proof. Consider the
  map $m_\beta: \Fp[x] \to \F$ defined by $m_\beta(f) = f(\beta)$. This
  is a homomorphism from $\Fp[x]$ into $\F$.

  If we restrict $m_\beta$ to $\Fp[x]/(g_\beta) \to \F$, we have an
  injective homomorphism. This follows from the fact (previously proven)
  that any $f \in \Fp[x]$ satisfying $f(\beta) = 0$ is a multiple of the
  minimal polynomial $g_\beta$.

  So $m_\beta$ is an isomorphism. We want to show it is surjective onto
  all of $\F$ for the right $\beta$. So choose $\beta$ a generator of
  the multiplicative group $\F^\times$. We then know that all elements
  of $\F$ are equal to $\beta^i$ for some $i$. We know that all powers
  $\beta_i$ are hit by $m_\beta$ since $m_\beta\parens{x^i} = \beta^i$.
  Thus $m_\beta$ is surjective onto all of $\F$.

  We conclude that $\F$ is isomorphic to $\Fp[x]/(g_\beta)$. Further,
  since $\F$ has $p^k$ elements, we know that there must be $p^k$
  elements in $\Fp[x]/(g_\beta)$. Thus we know that $g_\beta$ must have
  degree $k$.
\end{proof}

\begin{remark}
  In summary: we see that the Stanford chapter is really just a
  retelling of my own story in terms of ``minimal polynomials.''
\end{remark}

\subsection{All Finite Fields of Order $p^k$ Are Isomorphic}

\begin{remark}
  We have proven that a finite field $\F$ with order $p^k$ is isomorphic
  to a polynomial quotient field $\Fpmodg$ for some $k$-degree
  polynomial $g$ irreducible over $\Fp$. But we haven't proven that for
  distinct $k$-degree irreducible $g, g'$, $\Fpmodg \cong \Fpmod{g'}$.

  Note that it is not enough to try to simply associate $x \in \Fpmodg$
  with $x \in \Fpmod{g'}$. This will not yield a ring isomorphism, since
  $x^k \bmod g$ is not the same as $x^k \bmod g'$.
\end{remark}

\begin{remark}
  Here is how we will attack the problem. We've \emph{previously} shown
  that for every finite field $\F$ with order $p^k$, there exist
  homomorphisms from $\Fp[x]$ to $\F$ defined by $m_\beta(f) = f(\beta)$
  (for each $\beta \in \F$). We then saw that if we simply mod out by
  the minimal polynomial $g \in \Fp[x]$ for $\beta$, we have $m_\beta$
  injective on the quotient field $\Fpmodg$.

  We then showed that if you choose $\beta$ to be a multiplicative
  generator of $\F$, you insure that the span of $m_\beta$ will be all
  of $\F$. Since $\F$ has order $p^k$, we showed that the minimal
  polynomial $g$ for $\beta$ must have order $k$.

  What we will do is work \emph{backward}. We will \emph{start} with a
  $k$-degree polynomial $g$ irreducible over $\Fp$. We will show that
  for any $\F$ with order $p^k$, $g$ is a minimal polynomial for some
  $\beta \in \F$. Thus there is an isomorphism between $\Fpmodg$ and the
  subfield $\mathbb{G}_\beta$ generated by linear combinations of powers
  of $\beta$. But we know that for $k$-degree $g$ irreducible over
  $\Fp$, $\Fpmodg$ has $p^k$ elements. Thus the order of
  $\mathbb{G}_\beta$ must also be $p^k$, which means $\mathbb{G}_\beta =
  \F$.

  This will establish that for any $k$-degree irreducible $g$, every
  field $\F$ of order $p^k$ is isomorphic to $\Fpmodg$. Thus every pair
  of fields $\F, \F'$ with equal order are isomorphic.
\end{remark}

\begin{lemma}
  A $k$-degree polynomial $g$ irreducible over $\Fp$ divides $x^{p^k} -
  x$.
\end{lemma}

\begin{proof}
  Consider $\Fpmodg$. It has $p^k$ elements, and it is cyclically
  generated. Thus by Lagrange we know that for every $\alpha \in
  \Fpmodg$, $\alpha^{p^k} - \alpha \equiv 0 \pmod g$. In particular,
  take the element $x \in \Fpmodg$ and substitute this for
  $\alpha$. Then we know that $x^{p^k} - x \equiv 0 \pmod g$.

  This implies that $g$ must evenly divide $x^{p^k} - x$.
\end{proof}

\begin{lemma}
  Take any field $\F$ with order $p^k$. A degree-$k$ polynomial $g$
  irreducible over $\Fp$ can be factored into $k$ terms $(x - \beta_i)$
  for distinct elements $\beta_1, \ldots, \beta_k \in \F$.
\end{lemma}

\begin{proof}
  We first note that, because Lagrange, all $p^k$ elements $\beta \in
  \F$ are roots of the polynomial $x^{p^k} - x$. This thus factors into
  $\prod_{\beta\in\F} (x - \beta)$.

  Since $g$ is a factor of $x^{p^k} - x$, we know that there exists a
  subset of the $\beta$ such that $g = \prod_{i=1}^k (x - \beta_i)$.
  There are exactly $k$ of these factors because this is the degree of
  $g$.
\end{proof}

\begin{theorem}
  For any degree-$k$ polynomial $g$ irreducible over $\Fp[x]$, the
  polynomial quotient field $\Fpmodg$ can be put into isomorphism with
  \emph{any} field $\F$ with $p^k$ elements.
\end{theorem}

\begin{proof}
  We've just shown that there are $k$ elements $\beta_i \in \F$ that are
  roots of $g$. We know that $g$ is the minimal polynomial in $\Fp[x]$
  for these $\beta_i$. Let's pick a $\beta_i$ and simply call it
  $\beta$.

  Now, we've previously shown that the valuation map $m_\beta(f) =
  f(\beta)$ defines a homomorphism between $\Fpmodg$ and $\F$. In fact,
  we've shown that because $g$ is a minimal polynomial for $\beta$, this
  is in fact an isomorphism onto the span of $\beta$.

  The question then becomes: what is the span of $\beta$? It is clearly
  a subfield of $\F$, but is it all of $\F$? Yes. We know this because
  the field $\Fpmodg$ has exactly $p^k$ elements, since $g$ has degree
  $k$. Thus $m_\beta$ hits all of $\F$, and is an isomorphism between
  $\Fpmodg$ and $\F$.
\end{proof}

\begin{corollary}
  All finite fields $\F$ with $p^k$ elements are isomorphic.
\end{corollary}

\begin{remark}
  \TODO{This section doesn't seem natural yet.} I successfully
  translated Stanford's proof that every field $\F$ is isomorphic to
  some $\Fmodg$. I saw that my proof and Stanford's proof were
  fundamentally identical.

  I want to achieve a similar translation of this result that all fields
  (of equal order) are isomorphic.
\end{remark}

\begin{remark}
  We've shown that all fields of order $p^k$ are isomorphic to
  $\Fpmodg$, for some degree-$k$ polynomial $g$ irreducible over $\Fp$.

  We are left now with a single question: for every pair $p, k$, must
  there exist a field $\F$ with $p^k$ elements. Equivalently: does there
  always exist a degree-$k$ irreducible polynomial over $\Fp$?
\end{remark}

% Finished through 7.8.4! Page 22 of 26! Will try to power through
% eventually to finish this off!

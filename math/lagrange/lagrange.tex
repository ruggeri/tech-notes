\documentclass[11pt, oneside]{amsart}

\usepackage{geometry}
\geometry{letterpaper}

\usepackage{ned-common}
\usepackage{ned-calculus}
\usepackage{ned-linear-algebra}

\newcommand{\braket}[1]{|#1\rangle}
\newcommand{\sqtot}{\frac{\sqrt{2}}{2}}

\begin{document}

\title{Constrained Optimization}
\maketitle

\section{Univariate Unconstrained Optimization}

\begin{enumerate}
  \item  Given a function and (possibly) some constraints, you want to
  find the $x$ such that $f(x)$ is maximized.

  \item We will assume that $f$ is differentiable. This is actually a
  pretty strong assumption, but often holds.

  \item If $f$ is of one variable, then a local maximum is achieved
  when: $\fpartial{x} f(x)=0$ and $\fpartialsq{x} f(x)$ is negative. If
  $\fpartialsq{x} f(x)$ is positive, this is a local minimum.

  \item If $\fpartialsq{x} f(x)$ is zero, then we must look to further
  derivatives. I don't study these at this moment.
\end{enumerate}

\section{Multivariate Unconstrained Optimization}

\begin{enumerate}
  \item Say that $f:\R^n\to\R$ is differentiable; note that this is
  \emph{stronger} than the assumption that all partials exist. Take for
  instance:

  \begin{nedqn}
    f(x, y) = \setof{ x \,\text{if}\, y \ne x, \,\text{else}\, 0 }
  \end{nedqn}

  Partials exist wrt to $x$ and $y$ at $(0, 0)$, but this function is
  \emph{not} differentiable. In the case that $f$ is differentiable, its
  differential is the hyperplane defined by linear combinations of the
  partials.

  \item The gradient $\grad f$ defines the slope of the hyperplane
  tangent to $f$. When $\grad f$ is zero along each dimension, we
  \emph{might} be at an locally extreme value. This corresponds to the
  first derivative test.

  \item We next ask how the gradient will change as we move from $\vx$.
  This will corresponds to a second derivative test. We know that the
  analogue of the univariate second derivative is the \define{Hessian}:
  a matrix of mixed-partial derivatives $\frac{\partial^2}{\partial x_i
  \partial x_j} f$.

  \item Given a direction $\vu$, the Hessian $\mtxH$ tells us that the
  gradient will change by $\mtxH \vu$ by an infinitesimal change of
  $\vx$ in the direction of $\vu$. We can then ask: as the gradient
  changes by $\lambda \mtxH \vu$, will the value of $f(\vx + \lambda
  \vu)$ also change? For instance, if $\mtxH \vu$ is not a vector of
  zeros, we still may have $\fpartial{\lambda} f(\vx + \lambda \vu) = 0$
  if the gradient change is \emph{perpendicular} to $\vu$.

  \item If for every direction $\vu$ we have $\parens{\mtxH \vu}\tran
  \vu < 0$, then an infinitesimal change in any direction $\vu$ reduces
  the output of $f$. Likewise, if $\parens{\mtxH \vu}\tran \vu > 0$ for
  all $\vu$, then every direction we move in will increase the output of
  $f$.

  \item We call the first kind of matrix \emph{negative definite}, while
  the second kind is \emph{positive definite}. A zero gradient and
  negative definite Hessian implies a local maximum, whereas a zero
  gradient and positive definite Hessian implies a local minimum.

  \item Note that if a matrix is positive definite, then every diagonal
  entry must be positive, since $\ve_i\tran \mtxH \ve_i > 0$ and equals
  $\mtxH_{i, i}$. Likewise, a negative definite matrix satisfies
  $\ve_i\tran \mtxH \ve_i < 0$.

  \item Thus, if $\mtxH$ has a mix of positive and negative entries
  along the diagonal, it cannot represent an extreme value. A point such
  as this must represent a \define{saddle point}. That is: along one
  dimension we have $\ve_i\tran \mtxH \ve_i > 0$, but along another
  dimension we have $\ve_j\tran \mtxH \ve_j < 0$. A matrix where
  $\vv\tran \mtxH \vv$ is sometimes positive and other times negative is
  called \define{indefinite}. A zero gradient and an indefinite Hessian
  implies a saddle point, which is neither a local minimum or maximum.

  \item Can we determine definiteness simply by looking at the diagonal
  entries? The answer is no. Consider:

  \begin{nedqn}
    \parens{\cos\theta e_i + \sin\theta e_j}\tran
    \mtxH
    \parens{\cos\theta e_i + \sin\theta e_j}
  \eqcol
    \cos^2\theta \mtxH_{i, i}
    + 2\cos\theta \sin\theta \mtxH_{i, j}
    + \sin^2\theta \mtxH_{j, j}
  \end{nedqn}

  \noindent
  Here I have used symmetry of $\mtxH$ to note that $\mtxH_{i, j} =
  \mtxH_{j, i}$. Note that, as a function of $\theta$, this equation may
  touch or even go below zero, provided $\mtxH_{i, j}$ has opposite
  sign.

  \item We may use this equation to construct an example. Let $\mtxH_{i,
  i} = \mtxH_{j, j} = 1$. Let $\mtxH_{i, j} = \mtxH_{j, i} = -1$. Then,
  $\parens{1, 1} \mtxH \parens{1, 1}\tran = 0$.

  \item Likewise, we must not look at the diagonals, see they are all
  zero, and assume that $\vu\tran \mtxH \vu = 0$ for all $\vu$. Consider
  $\begin{bmatrix}0 & 1\\1 & 0\end{bmatrix}$.

  \item What about if $\vu\tran \mtxH \vu = 0$ for some $\vu$? In this
  case, the second-derivative test has failed. We cannot tell whether
  $g(t) = f(\vx + t \vu)$ will achieve a maximum, minimum, or neither at
  $\vx$.

  \item We call a matrix where $\vu\tran \mtxH \vu \geq 0$
  \define{positive semi-definite}. Likewise we define negative
  semi-definite. As described, we cannot conclude from a positive
  (negative) semi-definite Hessian that $\vx$ is a local minimum
  (maximum).

  We may, however, note, that a minimum (maximum) always implies a
  positive (negative) semi-definite Hessian.
\end{enumerate}

\section{Equality Constraints}

\begin{enumerate}
  \item Now say that you need to optimize a function given an equality
  constraint. That is, say that you are also given a function $g(x)$ and
  required that $g(x)=0$: now optimize $f(x)$.

  \item We will again assume that these are \define{smooth} functions
  (that all their derivatives exist). That is a mathematically strong
  assumption, but pretty realistic in many real-world problems.

  \item A helpful metaphor: assume $f$ maps coordinates in a national
  park to altitudes, while $g(x)=0$ defines a path through the national
  park. You want to find the point at which you reach the maximum
  altitude on the path.

  \item If $g$ truly defines a path, then you could equivalently define
  this path by $h(t)$ such that $t\in\R$ is a continuous mapping to
  points on the path. You could then differentiate $f(h(t))$ using the
  chain rule. This should give you the maximum.

  \item Finding this reparameterization of $g$ could be hard. Also, this
  approach would have difficulty generalizing if $g(x)=0$ defined a more
  complicated set than a path.
\end{enumerate}

\section{Lagrange Multipliers}

\begin{enumerate}
  \item Let us approach the problem differently. We know that we need an
  $x$ where the isoquant of $f$ is parallel to $g$. If that were not
  true, we could move a little along $g$ (in one direction or another)
  and move either up or down $f$.

  \item Isoquants of $f$ are perpendicular to $\grad f$. Likewise, the
  set $g(x)=0$ defines a manifold perpendicular to $\grad g$. So we know
  that $\grad f$ and $\grad g$ must lie in the same subspace. If they
  did not, we can project $\grad f$ onto the subspace perpendicular to
  $\grad g$ and move a little along the manifold to pick up some
  positive $f$ change.

  \item Therefore, we have $\grad f = \lambda \grad g$. The constant
  $\lambda$ is called the \define{Lagrange multiplier}. At most points
  $x$ (even those on the boundary), there is no such $\lambda$, because
  $\grad f$ and $\grad g$ are not aligned. But at a minimum or maximum
  there must be such a $\lambda$.

  \item Here is how I would solve the problem. I would set $\grad f =
  \lambda \grad g$. I would then solve for $x$ in terms of $\lambda$. I
  then plug this formula back into $g(x) = 0$. Even if $g$ originally
  consisted of many variables, the substitution makes it an equation in
  a single variable: $\lambda$. Therefore I can solve it.

  \item Having found the appropriate $\lambda$, I then use my formula to
  convert it back to $x$.

  \item We shall see that ``solving for $x$ in terms of $\lambda$''
  corresponds to ``optimizing profit with respect to a cost for
  pollution of $\lambda$.'' Then, by solving for the value of $\lambda$
  that satisfies $g(x) = 0$, we will find that price whereby the
  producer has no incentive to pollute.
\end{enumerate}

\section{Example}

\begin{enumerate}
  \item Let's say we want to maximize $f(x, y) = x + y$. We are subject
  to the constraint $g(x, y) = x^2 + y^2 - 1 = 0$. Basically: find the
  point that maximizes $x + y$ on the unit circle.

  \item I then do like so:

  \begin{nedqn}
    \grad f
  \eqcol
    \lambda \grad g
  \\
    \parens{1, 1}
  \eqcol
    \lambda \parens{2x, 2y}
  \\
    \parens{\tfrac{1}{2\lambda}, \tfrac{1}{2\lambda}}
  \eqcol
    \parens{x, y}
  \end{nedqn}

  \item I have divided by $\lambda$. Is that safe? Could $\lambda$ be
  zero? \TODO{I should argue why this is safe!}

  \item Having solved for $\lambda$, I focus on the constraint:

  \begin{nedqn}
    g(x, y)
  \eqcol
    x^2 + y^2 - 1 = 0
  \\
    2 \parensq{\tfrac{1}{2\lambda}}
  \eqcol
    1
  \\
    \half \lambda^{-2}
  \eqcol
    1
  \\
    \lambda
  \eqcol
    \frac{1}{\sqrt{2}}
  \intertext{which implies}
    \parens{x, y}
  \eqcol
    \parens{\frac{\sqrt{2}}{2}, \frac{\sqrt{2}}{2}}
  \end{nedqn}
\end{enumerate}

\section{Inequality Constraints}

\begin{enumerate}
  \item We have said that $\grad f(x^*) = \lambda \grad g(x^*)$ for some
  $\lambda$ at an $x^*$ that maximizes $f$ subject to a constraint that
  $g(x^*) = C$.

  \item What if we wish to allow $g(x^*) \leq C$? In this case, the
  optimum $x^*$ may incur $g(x^*) < C$. That is: $f(x^*)$ may be a local
  optimum of $f$ within the interior of the region defined by $g(x) <
  C$.

  \item Thus, when optimizing, we solve both ways: we may assume that
  $\lambda = 0$ and optimize $f(x)$ without constraint, and we may also
  assume that $\lambda \ne 0$, and that $\grad f = \lambda \grad g$. We
  should use the first solution if it obeys the constraint, else we must
  use the second solution.

  \item We may also \emph{combine} these terms. We ask the firm to
  optimize:

  \begin{nedqn}
    P(x) = f(x) - \lambda \parens{g(x) - C}
  \end{nedqn}

  \item We want to examine two kind of optima: (1) one which assumes
  that $\lambda = 0$, or (2) one which assumes that $g(x) - C = 0$.

  \item In this second case, note that $\fpartial{\lambda} P(x) = 0$.
  This is because no pollution above level $C$ is being created, and
  thus, at the optimal $x^*$, the firm is indifferent to changes in the
  tax on excess pollution.

  \item This allows us to transform the constrained problem into an
  unconstrained problem over $P(x, \lambda)$. The requirement that
  $\fpartial{\lambda} P = 0$ exactly specifies that $g(x) = C$.
\end{enumerate}

\section{Shadow Prices}

\begin{enumerate}
  \item A policy that sets a constraint that $g(x) \leq C$ is said to
  impose a \define{shadow price} $\lambda$ on pollution above level $C$.

  \item This is the price $\lambda$ such that the firm's optimal $x^*$
  for $f(x) - \lambda \parens{g(x) - C}$ would set $g(x^*) = C$.

  \item Note that the shadow price may be zero. This corresponds to the
  scenario where $g(x^*) \leq C$ even if we optimize $f$ without regard
  to constraint on the pollution $g$.

  \item By considering the shadow price $\lambda$, we could consider how
  this compares to the marginal suffering imposed on the victims of one
  more unit of pollution.

  \item A cap of $g(x) \leq C$ is not pareto optimal if the shadow price
  for pollution imposed on the firm is greater than the cost of an
  additional unit of pollution imposed on a victim. In that case, we
  would argue that we have set the cap too low.
\end{enumerate}

\section{KKT Conditions}

\begin{enumerate}
  \item We will list the conditions that should hold for a constrained
  optimization of $f$ subject to constraints that $g_i(x) \leq 0$ and
  $h_j(x) = 0$. The conditions are called \define{KKT conditions} after
  the people who defined this theorem.

  \item The theorem says that $x^*$ being an optimum of $f$ given the
  constraints implies there exists KKT multipliers $\setof{\mu_i},
  \setof{\lambda_j}$ such that the following conditions hold.

  \item First, we of course require that $g_i(x^*) \leq 0$ and $h_i(x^*)
  = 0$. Else, we would not have obeyed the constraints. This is called
  \define{primal feasibility}.

  \item We should also have that $\mu_i \geq 0$. These shadow prices
  should not go below zero, since we allow that $g_i(x) < 0$. This is
  called \define{dual feasibility}. Note that $\lambda_j$ may go below
  zero, since we may have to encourage the firm to incur $h_j(x^*) = 0$.

  \item We require that $\grad f(x^*) - \sum_i \mu_i \grad g_i(x^*) -
  \sum_j \lambda_j \grad h_j(x^*) = 0$. This is called
  \define{stationarity}. Note that $\mu_i$ and even $\lambda_j$ may be
  zero if the shadow price of imposing the corresponding constraint is
  zero.

  \item Last, $\mu_i g_i(x^*) = 0$. This is called \define{slackness}.
  It says that either $g_i(x^*) = 0$, or the shadow price $\mu_i$ is set
  to zero.

  \item Note that the last condition about slackness is necessary.
  Consider an interior point $x$ where $\grad f(x)$ and $\grad g(x)$ are
  aligned, but where $g(x)$ is still negative. Then the shadow price
  $\mu$ should still be zero, so that $\grad f(x) - \mu g(x) = \grad
  f(x) \ne 0$ encouraging you to increase production. But if you
  incorrectly set a shadow price $\mu > 0$, then you could discourage
  production and achieve stationarity: $\grad f(x) - \mu \grad g(x) =
  0$. You would be respecting both primal and dual feasibility.

  \item Only the violation of slackness would show you that you have not
  met all necessary conditions of a constrained optimum.

  \item Note that the KKT conditions are not \emph{sufficient} criteria;
  they are merely necessary. But we hope to be able identify and test
  just a few points that meet these criteria.

  \item Even assuming all $\mu_i \ne 0$, it might be hard to solve the
  system of equations implied by the stationarity condition. However, I
  believe you should always be able to solve via successive
  substitution. That is: you write one term in terms of the others, and
  successively substitute this value and repeat.
\end{enumerate}

\section{Worked KKT Example}

\begin{enumerate}
  \item This example comes from
  \href{http://www.math.ubc.ca/~israel/m340/kkt2.pdf}{LINK}.

  \item Let's try to maximize $f(x, y) = xy$ subject to the constraints
  that $x + y^2 \leq 2$ and $x \geq 0, y \geq 0$.

  \item We thus wish to maximize, for the appropriate $\mu_1, \mu_2,
  \mu_3 \geq 0$:

  \begin{nedqn}
    q(x) = xy - \mu_1 \parens{x + y^2} + \mu_2 x + \mu_3 y
  \end{nedqn}

  \item By stationarity, we know that:

  \begin{nedqn}
    \grad q(x)
  \eqcol
    \vec{0}
  \intertext{which implies}
  \\
    \fpartial{x} q(x)
  \eqcol
    y - \mu_1 + \mu_2 = 0
  \\
    \fpartial{y} q(x)
  \eqcol
    x - 2 \mu_1 y + \mu_3 = 0
  \end{nedqn}

  \item We will now examine the implications of complementary slackness.
  Let's first assume that $\mu_1 = 0$. Then we conclude that $y =
  -\mu_2$ and $x = -\mu_3$. We are supposed to require that $\mu_2,
  \mu_3 \geq 0$ (dual feasibility). But if $\mu_2 > 0$, then that would
  imply $y = -\mu_2 < 0$, which violates primal feasibility. So we must
  conclude $\mu_2 = 0$, which implies that $y = 0$. Likewise $x = 0$.

  This gives us the critical point $(x, y) = (0, 0)$. Note that any
  other point $(x \ne 0, 0), (0, y \ne 0)$ would give the same value
  $f(x, y) = xy = 0$. However, these are \emph{not} critical points.
  Take $x \ne 0$. Then $\fpartial{y} q(x) = x + \mu_3 > 0$ for any
  choice $\mu_3 \geq 0$. That is: we could improve the objective by
  increasing $y$. This is another way of showing that a critical point
  must set $x = 0$.

  \item Let's next assume that $\mu_1 \ne 0$. Then we know, from
  complementary slackness, that $x + y^2 = 2$.

  Consider $x = 0$. Then this implies that $y = \sqrt{2}$. This implies
  that $\mu_3 = 0$, by complementary slackness. But then note that $x =
  2 \mu_1 y > 0$. This contradicts the assumption that $x = 0$.

  When considering $\parens{0, \sqrt{2}}$, we note this is not a
  critical point unless there is a cost imposed on increasing $x$: this
  comes from $\mu_1 > 0$. But if so, then marginally we would want to
  decrease $y$ (to gain from the cost $\mu_1$), since this costs nothing
  with regard to our objective (since $\fpartial{y} f(0, y) = 0$).

  This explains why we obtained a contradiction, rather than identified
  a critical point.

  \item So we must have $x > 0$. This implies that $\mu_2 = 0$. Thus $y
  = \mu_1 > 0$. That in turn implies that $\mu_3 = 0$ (again by
  slackness).

  By substitution, we have that $x - 2 \mu_1 y + \mu_3 = x - 2 y^2 + 0
  =0$. Thus, $x = 2 y^2$. By plugging into $x + y^2 = 2$, we recover $y
  = \sqrt{\frac{2}{3}}$.

  Similarly, we could have said $y^2 = \frac{x}{2}$. Plugging this in
  gives us $x + \frac{x}{2} = 2$, implying $x = \frac{4}{3}$.

  This gives us a second critical point to consider:
  $\parens{x, y} = \parens{\frac{4}{3}, \sqrt{\frac{2}{3}}}$.

  \item We may easily see that $f(0, 0) = 0$, while $f(\frac{4}{3},
  \sqrt{\frac{2}{3}}) > 0$. Thus we have found our constrained optimum!
\end{enumerate}

\end{document}
